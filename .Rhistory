auto.arima(kings) # ARIMA(0,1,1)
# The result is aligned with previous calculation using diff() & acf()
# Autoregression (AR Model) ####
# Current observed value Y(t) depends on previous value Y(t-1), Y(t-2),...
# volcanic dust veil index in the northern hemisphere,
# from 1500-1969 (original data from Hipel and Mcleod, 1994
vc = scan("http://robjhyndman.com/tsdldata/annual/dvi.dat", skip=1)
ts.vc = ts(vc,start=c(1500))
ar(ts.vc)
plot.ts(ts.vc)
# Random variations seem constant over time, then Addictive (mô hình cộng hưởng)
# can be appropriate. Dont have to calculate difference as sariance is independent
# over time
auto.arima(ts.vc) # ARIMA(1,0,2)
# However if we use BIC (Bayesian Information Criterion)
auto.arima(vc, ic = "bic") # ARIMA(2,0,0)
# 22.5.3 Prediction using ARIMA ####
arima1 = arima(ts.kings, order = c(0, 1, 1))
arima1
forecast1 = forecast.Arima(arima1, h = 5)
forecast1
plot(forecast1)
arima2 = arima(ts.vc, order = c(2, 0, 0))
arima2
forecast2 = forecast.Arima(arima2, h = 50)
forecast2
plot(forecast2)
# 22.1 DATA INPUT & PLOT ####
# The age of death of 42 successive kings of England starting with William the Conqueror
kings = scan("http://robjhyndman.com/tsdldata/misc/kings.dat", skip = 3)
install.packages("TTR")
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/Descriptive Statistic.R', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/Descriptive Statistic.R', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/22. Times Series Analysis.R', encoding = 'UTF-8', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('/Volumes/LIFE/0. Data Science/Phân tích dữ liệu với R/10. Linear Regression .R', encoding = 'UTF-8', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
pnorm(2, 2, 4)
pnorm(2, 2, 4)
x
X
X(10, 100)
matrix(nrow=row, ncol=col)
source('~/Documents/3. DSTI/Stat & ML/distribution.R', echo=TRUE)
c(seq(1,10))
rbinorm(10, 0.2)
rbinom(10, 0.2)
rbinom(1, 10, 0.2)
rbinom(10, 10, 0.2)
A = matrix(c(rbinom(1000, 10, 0.2), nrow=10, ncol = 100))
A
rbinom(100, 10, 0.2)
A = matrix(c(rbinom(1000, 1, 0.2), nrow=10, ncol = 100))
A
rbinom(100, 1, 0.2)
A = matrix(c(rbinom(1000, 1, 0.2), nrow=10, ncol = 100))
A
A = matrix(c(rbinom(1000, 1, 0.2)), nrow=10, ncol = 100)
A
A = matrix(c(rbinom(1000, 1, 0.2)), nrow=10, ncol = 100, byrow = F)
A
A[1:10,]
A[c(1, 3, 4),]
c(seq(1, 2, 0.1), seq(7, 5, -0.5))
A[, 90:]
A[, 90:100]
A[-2, ]
A[-2, ]
A[c(-2, -5), ]
l = list(a = seq(1, 10, 0.5))
l
500, replace = T, prob = c(0.1, 0.7, 0.2))
sample(c("blue", "red", "yellow"), 500, replace = T, prob = c(0.1, 0.7, 0.2))
p = sample(c("blue", "red", "yellow"), 500, replace = T, prob = c(0.1, 0.7, 0.2))
p2 = factor(p)
p2
source('/Volumes/LIFE/0. Data Science/Data Society/Introduction to R and Visualization/Intro to R and Visualization.R')
E <- D * 33
setwd("~/")
list(p2, 1: 10)
k = matrix(data = 0, nrow = 3, ncol = 2)
k[,1] = p2[1:3]
k[,2] = 1:3
k
k = matrix(data = 0, nrow = 3, ncol = 2)
k
k[,1] = p2[1:3]
k
p = sample(c("blue", "red", "yellow"), 500, replace = T, prob = c(0.1, 0.7, 0.2))
p2 = factor(p)
p2
k = matrix(data = 0, nrow = 3, ncol = 2)
k
k[,1] = p2[1:3]
k
k[,2] = 1:3
k
rnif(1)
runif(10)
simuber <- function(n,p) {
x = c() # empty vector
for (i in 1:n) {
u = runif(1)
if (u<(1-p)) then x=c(x, 0)
else x = c(x, 1)
}
simuber = x
}
simuber <- function(n,p) {
x = c() # empty vector
for (i in 1:n) {
u = runif(1)
if (u<(1-p)) x=c(x, 0)
else x = c(x, 1)
}
simuber = x
}
simuber(100, 0,2)
simuber(100, 0.2)
simuber <- function(n,p) {
x = c() # empty vector
for (i in 1:n) {
u = runif(1)
if (u<(1-p)) {x=c(x, 0)}
else {x = c(x, 1)}
}
simuber = x
}
simuber(100, 0.2)
simuber
simuber <- function(n,p) {
x = c() # empty vector
for (i in 1:n) {
u = runif(1)
if (u<(1-p)) {x=c(x, 0)}
else {x = c(x, 1)}
}
return(x)
}
simuber(100, 0.2)
s
s = matrix(simuber(100, 0.2), nrow = 10)
s
s = matrix(simuber(1000, 0.2), nrow = 10)
s
simuber <- function(n,p) {
x = c() # empty vector
for (i in 1:n) {
u = runif(1)
if (u<(1-p)) {x=c(x, 0)}
else {x = c(x, 1)}
}
simuber = x
}
s = matrix(simuber(1000, 0.2), nrow = 10)
s
barplot(table(s)/1000)
par(mfrow = 1)
par(mfrow = c(1,1)
barplot(table(s)/1000)
par(mfrow = c(1,1))
barplot(table(s)/1000)
s = matrix(simuber(1000, 0.8), nrow = 10)
s
par(mfrow = c(1,1))
barplot(table(s)/1000)
s = matrix(simuber(1000, 0.2), nrow = 10)
s
par(mfrow = c(1,1))
barplot(table(s)/1000)
barplot(table(s)/1000)
barplot(table(s)/1000, ylab = "percent")
barplot(table(s)/1000, height = 2,ylab = "percent")
barplot(table(s)/1000, height = 1, ylab = "percent")
s = matrix(simuber(1000, 0.2), nrow = 10)
s
par(mfrow = c(1,1))
barplot(table(s)/1000, height = 1, ylab = "percent")
barplot(table(s)/1000, ylab = "percent")
barplot(table(s)/1000, height = 0.8, ylab = "percent")
barplot(table(s)/1000, ylab = "percent")
barplot(table(s)/1000, ylim = 2, ylab = "percent")
barplot(table(s)/1000, ylim = c(0, 2), ylab = "percent")
barplot(table(s)/1000, ylim = c(0, 1), ylab = "percent")
barplot(table(s)/1000, ylim = c(0, 1), ylab = "percent")
setwd("~/Documents/3. DSTI/Stat & ML")
extra
extra = read.csv('extra.txt')
extra
table(extra)
extra = read.csv('extra.txt')
View(table)
View(extra)
hist(extra)
extra = read.csv('extra.txt')
hist(extra)
hist(c(1, 2, 3, 4, 5, 6, 7, 8, 8, 9))
data1 = read.csv('data1.txt')
hist(data1)
hist(igfi)
#### DESCRIPTIVE STATISTICS ####
#### People heights (20) ####
height = c(162, 160, 157, 155, 167, 160, 161, 153, 149, 157,
159, 164, 150, 162, 168, 165, 156, 157, 154, 157)
mean(height) # parameter
sample5 = sample(height, 5)
sample5
mean(sample5) # sample estimate
sample10 = sample(height, 10)
sample10
mean(sample10)
# Note: Continuous measurement: Age, Height, Weight
#       Discrete measurement: Ordinal, Groups
#### Summary ####
igfdata = read.table("http://ykhoa.net/r/R-data/igf.txt",
header = TRUE, na.strings = ".")
View(igfdata)
names(igfdata)
head(igfdata)
mean(igfdata$age)
var(igfdata$age)
sd(igfdata$age)
summary(igfdata$age)
install.packages("psych")
library(psych)
describe(igfdata)
describe(igfdata, skew = F, ranges = F)
describeBy(igfdata, group = c("sex", "ethnicity"), skew = F, ranges = F)
op = par(mfrow = c(2, 3))
hist(igfi)
hist(igfbp3)
hist(als)
hist(pinp)
hist(ictp)
hist(p3np)
#### Tabular Summary ####
install.packages("psych")
hist(igfi)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
factor(data1)
View(data1)
table(data1)
data1['green']
data1 = read.csv('data1.txt')
View(data1)
table(data1)
data1['green']
ls()
rm(list=ls())
dir()
data1 = read.csv('data1.txt')
View(data1)
table(data1)
data1 = table(data1)
A = read.table('data1.txt')
View(A)
data1 = read.csv('data1.txt')
data1 = table(data1)
View(data1)
hist(data1)
pie(data1[, 2], labels = data1[, 1], main = "Pie chart")
data1[, 2]
data1[, 1]
data1[, :]
data1[, 1:]
data1[, 1:5]
data1[1, 3]
data1["data1"]
data2 = read.table('data2.txt', sep = " ")
View(data2)
data2 = read.table('data2.txt', sep = "\n")
View(data2)
data3 = read.csv('data3.txt')
data3 = table(data3)
View(data3)
hist(data3)
data2 = read.csv('data2.txt', sep = "\n")
data2 = table(data2)
View(data2)
hist(data1$Freq, labels = data1$data1, main = "Histogram")
data1.is.dataframe()
data1$data1
data1.as.data.frame()
as.data.frame(data1)
data1$data1
hist(data1$Freq, labels = data1$data1, main = "Histogram")
)
hist(data1)
data[1,]
data[1:5,]
data1 = read.csv('data1.txt')
data1 = table(data1)
is.data.frame
is.data.frame(data1)
data1 = read.table('data1.txt')
View(data1)
table(data1)
is.data.frame(data1)
pie(data1)
pie(s)
s = table(data1)
pie(s)
s
s/sum(s)
title('Repartition of colors of eyes')
data2 = read.table('data2.txt', sep = "\n")
View(data2)
table(data2)
hist(table)
t = table(data2)
hist(t)
is.data.frame(data2)
View(data2)
barplot(t)
View(t)
data2$data2
data2$V1
install.packages('plyr')
install.packages("plyr")
library(plyr)
factor(data2)
data2$V1
factor(data2$V1)
factor(data2$V1, labels = c("very bad", "bad", "quite good", "good", "excellent"))
data2
t = table(data2)
barplot(t)
data2 = factor(data2$V1, labels = c("very bad", "bad", "quite good", "good", "excellent"))
t = table(data2)
barplot(t)
data3 = read.table('data3.txt')
View(data3)
View(data3)
data2 = read.table('data2.txt', sep = "\n")
data2 = factor(data2$V1, labels = c("very bad", "bad", "quite good", "good", "excellent"))
t = table(data2)
barplot(t)
d2 = factor(data2$V1, labels = c("very bad", "bad", "quite good", "good", "excellent"))
t = table(d2)
barplot(t)
t = table(d2)
d2 = factor(data2$V1, labels = c("very bad", "bad", "quite good", "good", "excellent"))
data2 = read.table('data2.txt', sep = "\n")
View(data2)
d2 = factor(data2$V1, labels = c("very bad", "bad", "quite good", "good", "excellent"))
View(d2)
barplot(table(d2))
barplot(table(d2))
data3 = read.table('data3.txt')
View(data3)
data3 = table(data3)
View(data3)
barplot(data3)
table(d2)
barplot(table(d2))
table(d2)
d2 = factor(data2$V1, levels = c("very bad", "bad", "quite good", "good", "excellent"))
table(d2)
barplot(table(d2))
s/sum(s)
d2/sum(d2)
d2 = table(d2/sum(d2))
d2 = table(d2)/sum(d2)
d2 = factor(data2$V1, levels = c("very bad", "bad", "quite good", "good", "excellent"))
tabled2 = table(d2)/sum(table(d2))
barplot(tabled2)
barplot(tabled2, height = 1)
barplot(tabled2)
barplot(tabled2, ylim = c(0,1))
barplot(tabled2, ylim = c(0, 0.6))
data4 = read.table('data4.txt')
View(data4)
data4 = read.table('data4.txt')
View(data4)
data4$group = as.numberic(cut(data4$group, 6))
library(Hmisc)
data4$group = as.numberic(cut(data4$group, 6))
data4$group = as.numeric(cut(data4$group, 6))
data4$group = as.numeric(cut2(data4$group, g=3))
numdata4
data4
data4$group = as.numeric(cut2(data4$group, g=3))
View(data4)
split(data4, cut(data4$V1), 3)
hist(data4)
hist(data4, breaks = seq(0, 0.0, 0.1))
hist(data4, breaks = c(seq(0, 0.0, 0.1)))
hist(data4, breaks = seq(0, 0.5, 0.1))
data4 = read.table('data4.txt')
hist(data4, breaks = seq(0, 0.5, 0.1))
data3 = read.table('data3.txt')
data3 = table(data3)
View(data3)
barplot(data3)
unique(data3[, 1])
data3 = table(data3)
unique(data3[,1])
data3 = read.table('data3.txt')
unique(data3[,1])
data3 = table(data3)
View(data3)
data4 = read.table('data4.txt')
hist(data4, breaks = seq(0, 0.5, 0.1))
c3
c3 = c(rep(1, 2, 5), 500)
c3
c3 = c(rep((1, 2, 5), 500))
c3
c3 = rep(seq(1, 2, 5), 500))
hist(data4[, 1])
hist(data4[,1], freq = F)
hist(data4[,1], freq = F, ylim = 3.0)
hist(data4[,1], freq = F, ylim = c(0.0, 3.0))
c3 = rep(seq(1, 2, 5), 500)
c3
c3 = rep(c(1, 2, 5), 500)
c3
plot(data3[1,]/500, type = "p")
plot(data3/500, type = "p")
plot(data3/500, type = "l")
plot(data3/500, type = "h")
H = hist(data4[,1], freq = F, ylim = c(0.0, 3.0))
names(H)
H$counts
H$density
H$breaks
H$mids
H$xname
H$equidist
hist(data4, breaks = c(seq(0,0.5, 0.1), 0.8, 1, 1.2))
H$equidist
hist(data4, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 1.2))
H$equidist
hist(data4, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
H$equidist
hist(data4, freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
H$equidist
H1 = hist(data4, freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
H1$equidist
H1 = hist(data4, freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
H1 = hist(data4, freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
Hl = hist(data4, freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
Hl$equidist
names(Hl)
Hl = hist(data4[,1], freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
mean(data4[,1])
Hl = hist(data4[,1], freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
names(Hl)
Hl = hist(data4[,1], freq = F, breaks = c(seq(0, 0.6, 0.1), 0.7, 1, 2.2))
Hl = hist(data4[,1], freq = F, breaks = c(seq(0, 0.6, 0.1), 1, 2.2))
1/mean(data4[,1])
plot(1:10, 1:10, type="l")
Hl = hist(data4[,1], freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
data4 = read.table('data4.txt')
Hl = hist(data4[,1], freq = F, breaks = c(seq(0, 0.6, 0.1), 0.8, 1, 2.2))
hist(data4[, 1])
A = read.table('extra.txt')
dim(A)
graphics.off()
hist(A[,1], breaks = 25)
hist(A[,1], breaks = 100)
x = seq(-2,6,0.01)
var(A[1,])
var = var(A[1,])
y = dnorm(x, mean = 2, var = var )
plot(x,y,type ="l")
y = dnorm(x, mean = 2, var = 1 )
plot(x,y,type ="l")
y = dnorm(x, mean = 2, 1 )
plot(x,y,type ="l")
hist(A[,1], breaks = 150, freq = F)
